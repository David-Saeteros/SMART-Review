{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19087b2",
   "metadata": {},
   "source": [
    "# Classification Analysis Notebook\n",
    "\n",
    "Aquest notebook executa el codi per analitzar i classificar els articles inclosos. Si la variable `test` és `True`, es processen només els 5 primers articles; si és `False`, es processa tot el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dfd8f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/davidgallardo-pujol/Documents/GitHub/SMART-Review/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import concurrent.futures\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Variable per controlar el mode test: True només per 5 casos, False per tot el dataset\n",
    "test = True  # Canvia a False per processar tot el dataset\n",
    "\n",
    "# Afegir el directori de scripts al camí de Python\n",
    "scripts_dir = os.path.abspath('../scripts')\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.insert(0, scripts_dir)\n",
    "\n",
    "# Importa funcions de main.py\n",
    "from main import consult_model, extract_json_block, compute_global_classification, create_multiple_category_chart\n",
    "\n",
    "# File paths\n",
    "data_path = os.path.join(os.getcwd(), \"data\")\n",
    "classified_file = os.path.join(data_path, \"included_articles_classified.xlsx\")\n",
    "original_file = os.path.join(data_path, \"df_articles_results_classified.xlsx\")\n",
    "\n",
    "# Models LLM a utilitzar\n",
    "models = [\n",
    "    \"mistral-small-24b-instruct-2501\",\n",
    "    \"qwen2.5-7b-instruct-1m\",\n",
    "    \"phi-3-mini-4k-instruct\",\n",
    "    \"llama-3.2-3b-instruct\"\n",
    "]\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_abstract(model_name, title, abstract):\n",
    "    \"\"\"Query LLM to classify the abstract according to study design, conditions, etc.\"\"\"\n",
    "    article_text = f\"Title: {title}\\nAbstract: {abstract}\"\n",
    "    \n",
    "    prompt = (\n",
    "        \"You are a research assistant specialized in systematic reviews of mental health and employment interventions.\\n\\n\"\n",
    "        \"Task:\\n\"\n",
    "        \"Classify the following study according to these categories:\\n\\n\"\n",
    "        \"1. Study Design (select one):\\n\"\n",
    "        \"   - RCT (Randomized Controlled Trial)\\n\"\n",
    "        \"   - Quasi-experimental (Non-randomized studies with a control group)\\n\"\n",
    "        \"   - Systematic review (Systematic review or meta-analysis)\\n\"\n",
    "        \"   - Observational (Cohort studies, case-control, cross-sectional)\\n\"\n",
    "        \"   - Theoretical/Other (Conceptual, methodological, or narrative review)\\n\\n\"\n",
    "        \"2. Mental Health Condition (select all that apply):\\n\"\n",
    "        \"   - Depression\\n\"\n",
    "        \"   - Anxiety\\n\"\n",
    "        \"   - Schizophrenia\\n\"\n",
    "        \"   - Bipolar\\n\"\n",
    "        \"   - Personality disorders\\n\"\n",
    "        \"   - General mental health\\n\"\n",
    "        \"   - Multiple specific conditions\\n\"\n",
    "        \"   - Other (please specify)\\n\\n\"\n",
    "        \"3. Intervention Type (select all that apply):\\n\"\n",
    "        \"   - Supported employment\\n\"\n",
    "        \"   - Vocational rehabilitation\\n\"\n",
    "        \"   - Job search assistance\\n\"\n",
    "        \"   - Skills training\\n\"\n",
    "        \"   - Workplace accommodations\\n\"\n",
    "        \"   - Return-to-work programs\\n\"\n",
    "        \"   - Multiple interventions\\n\"\n",
    "        \"   - Other (please specify)\\n\\n\"\n",
    "        \"4. Outcome Measures (select all that apply):\\n\"\n",
    "        \"   - Employment rate\\n\"\n",
    "        \"   - Job retention\\n\"\n",
    "        \"   - Income/earnings\\n\"\n",
    "        \"   - Work functioning\\n\"\n",
    "        \"   - Mental health improvement\\n\"\n",
    "        \"   - Quality of life\\n\"\n",
    "        \"   - Multiple outcomes\\n\"\n",
    "        \"   - Other (please specify)\\n\\n\"\n",
    "        \"Important: Output must be a JSON with this structure:\\n\"\n",
    "        \"{\\n\"\n",
    "        \"  \\\"study_design\\\": \\\"CATEGORY\\\",\\n\"\n",
    "        \"  \\\"mental_health_condition\\\": [\\\"CONDITION1\\\", \\\"CONDITION2\\\"],\\n\"\n",
    "        \"  \\\"intervention_type\\\": [\\\"INTERVENTION1\\\", \\\"INTERVENTION2\\\"],\\n\"\n",
    "        \"  \\\"outcome_measures\\\": [\\\"OUTCOME1\\\", \\\"OUTCOME2\\\"]\\n\"\n",
    "        \"}\\n\\n\"\n",
    "        \"Article:\\n\"\n",
    "        f\"{article_text}\\n\\n\"\n",
    "        \"Very Important: Output only a JSON object with no additional text.\"\n",
    "    )\n",
    "    \n",
    "    url = \"http://127.0.0.1:1234/v1/chat/completions\"\n",
    "    request_body = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in systematic reviews of mental health and employment interventions.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.1,\n",
    "        \"max_tokens\": 500\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=request_body, headers={\"Content-Type\": \"application/json\"})\n",
    "        response_text = response.text\n",
    "        response_json = json.loads(response_text)\n",
    "        generated_text = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        # Clean up the response to extract just the JSON\n",
    "        cleaned_text = generated_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        # For phi-3-mini model, extract the JSON block\n",
    "        if model_name == \"phi-3-mini-4k-instruct\":\n",
    "            cleaned_text = extract_json_block(cleaned_text)\n",
    "            \n",
    "        parsed_result = json.loads(cleaned_text)\n",
    "        return parsed_result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article with {model_name}: {e}\")\n",
    "        return {\n",
    "            \"study_design\": \"Error\",\n",
    "            \"mental_health_condition\": [\"Error\"],\n",
    "            \"intervention_type\": [\"Error\"],\n",
    "            \"outcome_measures\": [\"Error\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9718d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article(idx, row):\n",
    "    \"\"\"Processa un article individual: consulta tots els models i retorna els resultats.\"\"\"\n",
    "    article_id = idx + 1\n",
    "    print(f\"Processing article {article_id}\")\n",
    "    \n",
    "    title = row.get(\"Article Title\", \"\")\n",
    "    abstract = row.get(\"Abstract\", \"\")\n",
    "    \n",
    "    # Combine title and abstract if abstract is missing\n",
    "    if not abstract and title:\n",
    "        abstract = title\n",
    "    if not abstract and not title:\n",
    "        print(f\"Skipping article {article_id} - no title or abstract\")\n",
    "        return None, None\n",
    "    \n",
    "    model_results = {}\n",
    "    # Paral·lelitza les consultes a tots els models (operació I/O)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=len(models)) as executor:\n",
    "        future_to_model = {executor.submit(classify_abstract, model, title, abstract): model for model in models}\n",
    "        for future in concurrent.futures.as_completed(future_to_model):\n",
    "            model = future_to_model[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                model_results[model] = result\n",
    "            except Exception as e:\n",
    "                print(f\"Error getting result from {model}: {e}\")\n",
    "                model_results[model] = {\n",
    "                    \"study_design\": \"Error\",\n",
    "                    \"mental_health_condition\": [\"Error\"],\n",
    "                    \"intervention_type\": [\"Error\"],\n",
    "                    \"outcome_measures\": [\"Error\"]\n",
    "                }\n",
    "    \n",
    "    # Crear el registre per als resultats de tots els models\n",
    "    record = {\n",
    "        \"Article_ID\": article_id,\n",
    "        \"Article_Title\": title,\n",
    "        \"Abstract\": abstract,\n",
    "        \"DOI\": row.get(\"DOI\", \"\")\n",
    "    }\n",
    "    for model in models:\n",
    "        model_clean = model.replace(\"-\", \"_\")\n",
    "        result = model_results.get(model, {})\n",
    "        record[f\"{model_clean}_study_design\"] = result.get(\"study_design\", \"Unknown\")\n",
    "        record[f\"{model_clean}_mental_health\"] = \", \".join(result.get(\"mental_health_condition\", [\"Unknown\"]))\n",
    "        record[f\"{model_clean}_intervention\"] = \", \".join(result.get(\"intervention_type\", [\"Unknown\"]))\n",
    "        record[f\"{model_clean}_outcomes\"] = \", \".join(result.get(\"outcome_measures\", [\"Unknown\"]))\n",
    "    \n",
    "    # Calcular la classificació global basant-se en els resultats de tots els models\n",
    "    results_list = list(model_results.values())\n",
    "    global_record = {\n",
    "        \"Article_ID\": article_id,\n",
    "        \"Article_Title\": title,\n",
    "        \"Abstract\": abstract,\n",
    "        \"DOI\": row.get(\"DOI\", \"\"),\n",
    "        \"Study_Design\": compute_global_classification(results_list, \"study_design\"),\n",
    "        \"Mental_Health_Condition\": \", \".join(compute_global_classification(results_list, \"mental_health_condition\")),\n",
    "        \"Intervention_Type\": \", \".join(compute_global_classification(results_list, \"intervention_type\")),\n",
    "        \"Outcome_Measures\": \", \".join(compute_global_classification(results_list, \"outcome_measures\"))\n",
    "    }\n",
    "    \n",
    "    # Guarda el resultat de l'article com a fitxer JSON a la carpeta \"output/postprocessed\"\n",
    "    out_dir = os.path.join(\"./output\", \"postprocessed\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    article_output = {\n",
    "        \"Article_ID\": article_id,\n",
    "        \"Article_Title\": title,\n",
    "        \"Abstract\": abstract,\n",
    "        \"Model_Results\": model_results,\n",
    "        \"Global_Results\": {\n",
    "            \"Study_Design\": global_record[\"Study_Design\"],\n",
    "            \"Mental_Health_Condition\": global_record[\"Mental_Health_Condition\"].split(\", \"),\n",
    "            \"Intervention_Type\": global_record[\"Intervention_Type\"].split(\", \"),\n",
    "            \"Outcome_Measures\": global_record[\"Outcome_Measures\"].split(\", \")\n",
    "        }\n",
    "    }\n",
    "    output_file = os.path.join(out_dir, f\"article_{article_id}_classification.json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(article_output, f, indent=2)\n",
    "    \n",
    "    # Retorna els registres per a l'agregació\n",
    "    return record, global_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Funció principal per analitzar i classificar els articles inclosos basant-se en diverses dimensions:\n",
    "    - Disseny de l'estudi\n",
    "    - Condicions de salut mental\n",
    "    - Tipus d'intervenció\n",
    "    - Mesures d'resultat\n",
    "    \n",
    "    Aquesta funció:\n",
    "    1. Carrega el dataset original i filtra els estudis inclosos.\n",
    "    2. O carrega les dades classificades existents o consulta l'LLM per classificar els articles.\n",
    "    3. Genera visualitzacions per a les classificacions.\n",
    "    4. Proporciona estadístiques resum.\n",
    "    \"\"\"\n",
    "    print(\"Loading original dataset...\")\n",
    "    original_df = pd.read_excel(original_file)\n",
    "    \n",
    "    # Mapear valors de GlobalInclusion\n",
    "    global_inclusion_mapping = {\"Yes\": \"Included\", \"No\": \"Excluded\", \"Unclear\": \"Unclear\"}\n",
    "    original_df[\"GlobalInclusion\"] = original_df[\"GlobalInclusion\"].map(global_inclusion_mapping)\n",
    "    \n",
    "    # Filtrar només estudis inclosos\n",
    "    included_df = original_df[original_df[\"GlobalInclusion\"] == \"Included\"].copy()\n",
    "    # Si test és True, processa només els 5 primers articles\n",
    "    if test:\n",
    "        included_df = included_df.head(5)\n",
    "    print(f\"Processing only included studies: {len(included_df)} articles\")\n",
    "    \n",
    "    all_results = []\n",
    "    global_results = []\n",
    "    \n",
    "    # Si ja existeix el fitxer classificat, el carreguem\n",
    "    if os.path.exists(classified_file):\n",
    "        print(\"Classified file found. Loading data without querying LLM...\")\n",
    "        all_model_df = pd.read_excel(classified_file, sheet_name=\"All_Models\")\n",
    "        global_df = pd.read_excel(classified_file, sheet_name=\"Global_Decision\")\n",
    "        # Si test és True, només mantenim els 5 primers casos\n",
    "        if test:\n",
    "            all_model_df = all_model_df.head(5)\n",
    "            global_df = global_df.head(5)\n",
    "    else:\n",
    "        print(\"Classified file not found. Querying LLM to classify included studies...\")\n",
    "        # Paral·lelitza el processament dels articles amb ProcessPoolExecutor\n",
    "        with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "            futures = {executor.submit(process_article, idx, row): idx for idx, row in included_df.iterrows()}\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                record, global_record = future.result()\n",
    "                if record is not None:\n",
    "                    all_results.append(record)\n",
    "                    global_results.append(global_record)\n",
    "        \n",
    "        # Convertir els resultats en DataFrames\n",
    "        all_model_df = pd.DataFrame(all_results)\n",
    "        global_df = pd.DataFrame(global_results)\n",
    "        \n",
    "        # Guardar els resultats a Excel amb diverses fulles\n",
    "        with pd.ExcelWriter(classified_file) as writer:\n",
    "            all_model_df.to_excel(writer, sheet_name=\"All_Models\", index=False)\n",
    "            global_df.to_excel(writer, sheet_name=\"Global_Decision\", index=False)\n",
    "        \n",
    "        print(f\"Classification complete. Results saved to {classified_file}\")\n",
    "    \n",
    "    # Generar visualitzacions per a les decisions globals\n",
    "    print(\"Generating visualizations...\")\n",
    "    \n",
    "    figures_dir = os.path.join(os.getcwd(), \"figures\", \"charts\")\n",
    "    if not os.path.exists(figures_dir):\n",
    "        os.makedirs(figures_dir, exist_ok=True)\n",
    "    \n",
    "    # Visualització de Study Design\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    global_df[\"Study_Design\"].value_counts().plot(kind=\"bar\", color=\"green\")\n",
    "    plt.xlabel(\"Study Design\")\n",
    "    plt.ylabel(\"Number of Articles\")\n",
    "    plt.title(\"Distribution of Study Types (Included Studies)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, \"study_design_distribution.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualitzacions per camps multi-categoria\n",
    "    create_multiple_category_chart(global_df, \"Mental_Health_Condition\", \n",
    "                                  \"Mental Health Conditions Distribution\", \n",
    "                                  os.path.join(figures_dir, \"mental_health_distribution\"))\n",
    "    \n",
    "    create_multiple_category_chart(global_df, \"Intervention_Type\", \n",
    "                                  \"Intervention Types Distribution\", \n",
    "                                  os.path.join(figures_dir, \"intervention_distribution\"))\n",
    "    \n",
    "    create_multiple_category_chart(global_df, \"Outcome_Measures\", \n",
    "                                  \"Outcome Measures Distribution\", \n",
    "                                  os.path.join(figures_dir, \"outcomes_distribution\"))\n",
    "    \n",
    "    # Heatmap de condicions vs tipus d'intervenció\n",
    "    all_conditions = []\n",
    "    for conditions_str in global_df[\"Mental_Health_Condition\"].dropna():\n",
    "        conditions = [c.strip() for c in conditions_str.split(\",\")]\n",
    "        all_conditions.extend(conditions)\n",
    "    \n",
    "    all_interventions = []\n",
    "    for interventions_str in global_df[\"Intervention_Type\"].dropna():\n",
    "        interventions = [i.strip() for i in interventions_str.split(\",\")]\n",
    "        all_interventions.extend(interventions)\n",
    "    \n",
    "    unique_conditions = sorted(list(set(all_conditions)))\n",
    "    unique_interventions = sorted(list(set(all_interventions)))\n",
    "    \n",
    "    condition_intervention_matrix = pd.DataFrame(0, \n",
    "                                              index=unique_conditions, \n",
    "                                              columns=unique_interventions)\n",
    "    \n",
    "    # Omplir la matriu\n",
    "    for _, row in global_df.iterrows():\n",
    "        if pd.isna(row[\"Mental_Health_Condition\"]) or pd.isna(row[\"Intervention_Type\"]):\n",
    "            continue\n",
    "        \n",
    "        conditions = [c.strip() for c in row[\"Mental_Health_Condition\"].split(\",\")]\n",
    "        interventions = [i.strip() for i in row[\"Intervention_Type\"].split(\",\")]\n",
    "        \n",
    "        for condition in conditions:\n",
    "            for intervention in interventions:\n",
    "                if condition in condition_intervention_matrix.index and intervention in condition_intervention_matrix.columns:\n",
    "                    condition_intervention_matrix.loc[condition, intervention] += 1\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(condition_intervention_matrix, annot=True, cmap=\"YlGnBu\", fmt=\"d\")\n",
    "    plt.title(\"Mental Health Conditions vs Intervention Types (Included Studies)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(figures_dir, \"condition_intervention_heatmap.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Estadístiques resum\n",
    "    print(\"\\nSummary Statistics (Included Studies Only):\")\n",
    "    print(f\"Total number of included articles: {len(global_df)}\")\n",
    "    \n",
    "    if \"Study_Design\" in global_df.columns:\n",
    "        design_counts = global_df[\"Study_Design\"].value_counts()\n",
    "        print(\"\\nStudy Design Distribution:\")\n",
    "        print(design_counts)\n",
    "    \n",
    "    all_conditions = []\n",
    "    for conditions_str in global_df[\"Mental_Health_Condition\"].dropna():\n",
    "        conditions = [c.strip() for c in conditions_str.split(\",\")]\n",
    "        all_conditions.extend(conditions)\n",
    "    condition_counts = pd.Series(all_conditions).value_counts()\n",
    "    print(\"\\nMental Health Condition Distribution:\")\n",
    "    print(condition_counts)\n",
    "    \n",
    "    all_interventions = []\n",
    "    for interventions_str in global_df[\"Intervention_Type\"].dropna():\n",
    "        interventions = [i.strip() for i in interventions_str.split(\",\")]\n",
    "        all_interventions.extend(interventions)\n",
    "    intervention_counts = pd.Series(all_interventions).value_counts()\n",
    "    print(\"\\nIntervention Type Distribution:\")\n",
    "    print(intervention_counts)\n",
    "    \n",
    "    all_outcomes = []\n",
    "    for outcomes_str in global_df[\"Outcome_Measures\"].dropna():\n",
    "        outcomes = [o.strip() for o in outcomes_str.split(\",\")]\n",
    "        all_outcomes.extend(outcomes)\n",
    "    outcome_counts = pd.Series(all_outcomes).value_counts()\n",
    "    print(\"\\nOutcome Measures Distribution:\")\n",
    "    print(outcome_counts)\n",
    "    \n",
    "    print(f\"\\nResults have been saved to: {classified_file}\")\n",
    "    print(\"Visualizations have been saved to the 'figures' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
